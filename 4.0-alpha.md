# Pipeline
![pipeline](https://user-images.githubusercontent.com/26596196/40709218-1ed107e2-6428-11e8-9696-4442698ee7fb.png)
# Data Structures Flow of pages -> words
![image](https://user-images.githubusercontent.com/26596196/40709566-00447326-6429-11e8-885a-9f3e3e06eaba.png)

# Changes from the previous version
- eliminate the polygonal approximation
- no need for accurate baseline normalization
  - Simple LSTM still depends on good input size/position.
  - DN can be designed to learn normalization but trains slowly.

# Tesseract LSTM and Tensor Flow
- Tesseract LSTM (T-LSTM) came first, and only supports sequence
processing
- Tensor Flow is built for speed, on batches of fixed-size input, but can be
run from Tesseract. --> Google is working on it since 2016.
  - UPDATE: [tfnetwork.h](http://tesseract-ocr.github.io/4.0.0-beta.1/a01148_source.html) Encapsulation of an entire tensorflow graph as a Tesseract Network.
- An entire TF graph is treated as a Tesseract Network element.
- TF graph must be designed to support variable width inputs, or work only
on fixed-size images.

# References
[DAS 2016 tutorial slides](https://github.com/tesseract-ocr/docs/tree/master/das_tutorial2016)  
Slides
[#2: pipeline & data flow](https://github.com/tesseract-ocr/docs/blob/master/das_tutorial2016/2ArchitectureAndDataStructures.pdf),
[#6: LSTM](https://github.com/tesseract-ocr/docs/blob/master/das_tutorial2016/6ModernizationEfforts.pdf),
[#7: Multilingual OCR](https://github.com/tesseract-ocr/docs/blob/master/das_tutorial2016/7Building%20a%20Multi-Lingual%20OCR%20Engine.pdf)
have information about LSTM integration in Tesseract 4.0.

# Preprocessing Procedure
![image](https://user-images.githubusercontent.com/26596196/40817404-d67fbe4e-6584-11e8-848f-324c6b6b16d1.png)
Find the text lines and regions -> eventually make the box file in textline level (for LSTM)

# Training Procedure
### Overview
- Prepare training text 
  - texts divided by languages. [Source language data](https://github.com/tesseract-ocr/langdata)
  - unicharset (for each language): everything other than the text above and the wordlist 
- Rendor text to image + box file / create hand-made box files from existing image data
  - detail format is found [here](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00#creating-training-data)
- Starter traineddata (instead of unicharset and script_dir): required during feature extraction
  - lstm-unicharset: define character set -- do compression-recoding for complex scripts (Han, Hangual, Indic)). The unicode is re-encided using a sequence of smaller numbers. See the [code](http://tesseract-ocr.github.io/4.0.0-beta.1/a04038.html)
  - outputs by combine_lang_modelï¼šunicharcompress (=lstm-recoder), *lstm-punc-dawg, *lstm-word-dawg, *lstm-number-dawg
  - *config: providing control parameters
- create training data from the tif/box pairs
  -tesstrain (api to do everything related to training)

### Feature Extraction
Convolutional and Deep Belief nets hide the feature extraction within:
The


### Input
- The image reads in as a vector or matrix (determined by depth)
- The chars are re-encoded by the compress recorder

### output



  
  
  
  
